{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paa8rQnkSE-2"
      },
      "source": [
        "# 1.Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "edvIULJRQdo1"
      },
      "outputs": [],
      "source": [
        "# import libraries and dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cejgfE-sSTRX"
      },
      "source": [
        "# 2.Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYkbmryyUh6N"
      },
      "source": [
        "### 2.1  Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "hDlLPFKcSSdx",
        "outputId": "562cd09c-1cc8-48c5-ba54-672d2c6d6eef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sklearn.utils._bunch.Bunch</b><br/>def __init__(**kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/sklearn/utils/_bunch.py</a>Container object exposing keys as attributes.\n",
              "\n",
              "Bunch objects are sometimes used as an output for functions and methods.\n",
              "They extend dictionaries by enabling values to be accessed by key,\n",
              "`bunch[&quot;value_key&quot;]`, or by an attribute, `bunch.value_key`.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from sklearn.utils import Bunch\n",
              "&gt;&gt;&gt; b = Bunch(a=1, b=2)\n",
              "&gt;&gt;&gt; b[&#x27;b&#x27;]\n",
              "2\n",
              "&gt;&gt;&gt; b.b\n",
              "2\n",
              "&gt;&gt;&gt; b.a = 3\n",
              "&gt;&gt;&gt; b[&#x27;a&#x27;]\n",
              "3\n",
              "&gt;&gt;&gt; b.c = 6\n",
              "&gt;&gt;&gt; b[&#x27;c&#x27;]\n",
              "6</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 7);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "sklearn.utils._bunch.Bunch"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data= fetch_20newsgroups(subset='all',  shuffle=True, random_state=46)\n",
        "\n",
        "categories = [\n",
        "    'alt.atheism',\n",
        "    'talk.religion.misc',\n",
        "    'comp.graphics',\n",
        "    'sci.space'\n",
        "]\n",
        "data_train = fetch_20newsgroups(\n",
        "    subset=\"train\",\n",
        "    categories=categories,\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        "\n",
        ")\n",
        "data_test = fetch_20newsgroups(\n",
        "    subset='test',\n",
        "    categories=categories,\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        "\n",
        ")\n",
        "type(data_train)\n",
        "\n",
        "\n",
        "# print(data.train)\n",
        "# print(data.target_names[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r5FxF7C-80O",
        "outputId": "5b321cc2-26e2-40c7-faf7-ffb3c605a799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
          ]
        }
      ],
      "source": [
        "print(data_train.keys()) # check attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsQJi--m-8_v",
        "outputId": "e1b2c8e1-bfeb-4fc4-c794-fa3e4535efc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
          ]
        }
      ],
      "source": [
        "print(data_train.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW7qs3khEef_",
        "outputId": "953116e0-dac3-455b-eea0-f4505cad225c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From: Mark.Perew@p201.f208.n103.z1.fidonet.org\n",
            "Subject: Re: Comet in Temporary Orbit Around Jupiter?\n",
            "X-Sender: newtout 0.08 Feb 23 1993\n",
            "Lines: 15\n",
            "\n",
            "In a message of <Apr 19 04:55>, jgarland@kean.ucs.mun.ca writes:\n",
            "\n",
            " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
            " >writes:\n",
            "\n",
            "MB>                                                             So the\n",
            "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
            "\n",
            "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
            "\n",
            "Couldn't we just say periapsis or apoapsis?\n",
            "\n",
            " \n",
            "\n",
            "--- msged 2.07\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(data_train.data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7tTbntKBcTe",
        "outputId": "4a39a7c9-26ec-422f-e7ed-7a296ab2e56b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 3 2 ... 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(data_train.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybkrN9QSCnsT",
        "outputId": "f25f5f3b-40ed-4525-d775-e57e626c06c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.utils._bunch.Bunch'>\n"
          ]
        }
      ],
      "source": [
        "print(type(data_train))  # check type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKMt4B3uV0Wv"
      },
      "source": [
        "### 2.2 text preporcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LapQu_prV-eZ",
        "outputId": "a2767fc6-20e5-4dab-c70a-5a4d89824315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['comp.graphics', 'talk.religion.misc', 'sci.space', 'alt.atheism', 'sci.space']\n",
            "['sci.space', 'comp.graphics', 'comp.graphics', 'comp.graphics', 'comp.graphics']\n"
          ]
        }
      ],
      "source": [
        "data_train_category = []\n",
        "for i in data_train.target:\n",
        "    data_train_category.append(data_train.target_names[i])\n",
        "print(data_train_category[:5])\n",
        "\n",
        "\n",
        "data_test_category=[]\n",
        "for i in data_test.target:\n",
        "    data_test_category.append(data_test.target_names[i])\n",
        "print(data_test_category[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLSL904nJEuv",
        "outputId": "ea4a4d0c-94fb-4f0b-89c2-668d5b165722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2034"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# turn it into a dataframe\n",
        "\n",
        "data_df=pd.DataFrame(data.target,columns=['Category_No'])\n",
        "\n",
        "data_train_df = pd.DataFrame(data_train.target, columns=[\"label\"])\n",
        "data_test_df = pd.DataFrame(data_test.target, columns=[\"label\"])\n",
        "\n",
        "\n",
        "# data_df['Category_No'].value_counts()    # 了解每個類別的數量\n",
        "data_df['Text'] = data.data    # 將文字放入dataframe\n",
        "data_train_df['Text']=data_train.data\n",
        "data_test_df['Text'] = data_test.data\n",
        "\n",
        "\n",
        "# data_df['Category_Name']=data_category  #將類別名稱放入dataframe\n",
        "\n",
        "data_train_df[\"category\"] = data_train_category\n",
        "data_test_df[\"category\"] = data_test_category\n",
        "\n",
        "# data_train_df=data_train_df[:16000]\n",
        "data_train_df.shape[1]  # the number of columns\n",
        "data_train_df.shape[0] # the number of rows\n",
        "# data_test_df.shape[0]\n",
        "# data_df.shape[0]\n",
        "\n",
        "# data_train_df['Text'].value_counts()  # counting the text\n",
        "\n",
        "# print(data_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "EJzY1UbXBBSd"
      },
      "outputs": [],
      "source": [
        "# text preprocessing\n",
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "        self.word_to_idx = self.vocab\n",
        "        self.idx_to_word = {0: \"<PAD>\", 1: \"<UNK>\"}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return text.lower().split()\n",
        "\n",
        "    # **** 關鍵改進1: min_freq=5 (從3改為5，大幅減少詞彙) ****\n",
        "    def build_vocab(self, texts, min_freq=4):\n",
        "        word_counts = Counter()\n",
        "        for text in texts:\n",
        "            words = self.tokenize(text)\n",
        "            word_counts.update(words)\n",
        "\n",
        "        idx = 2\n",
        "        for word, count in word_counts.items():\n",
        "            if count >= min_freq:\n",
        "                self.vocab[word] = idx\n",
        "                self.idx_to_word[idx] = word\n",
        "                idx += 1\n",
        "\n",
        "        print(f\"Vocabulary size: {len(self.vocab)}\")\n",
        "        return self.vocab\n",
        "\n",
        "    def text_to_sequence(self, text, max_len):\n",
        "        words = self.tokenize(text)\n",
        "        sequence = [self.vocab.get(word, 1) for word in words]\n",
        "        if len(sequence) < max_len:\n",
        "            sequence += [0] * (max_len - len(sequence))\n",
        "        else:\n",
        "            sequence = sequence[:max_len]\n",
        "        return sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "7kjsPGxtBG_s"
      },
      "outputs": [],
      "source": [
        "# Dataset using DataFrame\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, preprocessor, max_len=30):\n",
        "        self.df = df\n",
        "        self.preprocessor = preprocessor\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = row[\"Text\"]\n",
        "        label = row[\"label\"]\n",
        "        sequence = self.preprocessor.text_to_sequence(text, self.max_len)\n",
        "        return torch.LongTensor(sequence), torch.LongTensor([label])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oCjROylBHfN"
      },
      "outputs": [],
      "source": [
        "# TextCNN Model - \n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(\n",
        "        self, vocab_size, embed_dim, num_filters, filter_sizes, num_classes, dropout=0.5\n",
        "    ):\n",
        "        super(TextCNN, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "       \n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(embed_dim, num_filters, kernel_size=f, padding=f-1)\n",
        "            for f in filter_sizes\n",
        "        ])\n",
        "\n",
        "       \n",
        "        self.bns = nn.ModuleList([\n",
        "            nn.BatchNorm1d(num_filters)\n",
        "            for _ in filter_sizes\n",
        "        ])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "      \n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding\n",
        "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
        "        embedded = self.dropout(embedded)\n",
        "        embedded = embedded.transpose(1, 2)  # (batch, embed_dim, seq_len)\n",
        "\n",
        "        # ****Conv1d + BatchNorm + ReLU ****\n",
        "        conv_results = []\n",
        "        for conv, bn in zip(self.convs, self.bns):\n",
        "            c = conv(embedded)  # (batch, num_filters, seq_len)\n",
        "            c = bn(c)  # Batch Norm\n",
        "            c = self.relu(c)\n",
        "            p = torch.max_pool1d(c, c.size(2)).squeeze(2)  # (batch, num_filters)\n",
        "            conv_results.append(p)\n",
        "\n",
        "  \n",
        "        cat = torch.cat(conv_results, 1)  # (batch, num_filters * len(filter_sizes))\n",
        "        cat = self.dropout(cat)\n",
        "\n",
        "    \n",
        "        out = self.fc(cat)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnrxN2grpyCX"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, num_classes):\n",
        "    model.train()\n",
        "    best_val_acc = 0\n",
        "    patience = 5\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_texts, batch_labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_texts)\n",
        "            loss = criterion(outputs, batch_labels.squeeze())\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "          \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += batch_labels.size(0)\n",
        "            correct += (predicted == batch_labels.squeeze()).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "            f\"Train Loss: {train_loss:.4f} Train Acc: {train_acc:.2f}% | \"\n",
        "            f\"Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}%\"\n",
        "        )\n",
        "\n",
        "    \n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"\\n✓ early stoppping at Epoch {epoch+1}\")\n",
        "                model.load_state_dict(torch.load('best_model.pt'))\n",
        "                break\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_texts, batch_labels in dataloader:\n",
        "            outputs = model(batch_texts)\n",
        "            loss = criterion(outputs, batch_labels.squeeze())\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += batch_labels.size(0)\n",
        "            correct += (predicted == batch_labels.squeeze()).sum().item()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def predict_news(text, model, preprocessor, max_len=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        seq = preprocessor.text_to_sequence(text, max_len)\n",
        "        x = torch.LongTensor(seq).unsqueeze(0)\n",
        "        out = model(x)\n",
        "        prob = torch.softmax(out, dim=1)\n",
        "        cls = torch.argmax(prob, dim=1).item()\n",
        "        return cls, prob[0][cls].item()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk5C2BoDpyHK",
        "outputId": "270fac7a-359a-4d8d-dfee-88fd98e912d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocabulary from training data...\n",
            "Vocabulary size: 14108\n",
            "\n",
            "Training model...\n",
            "Epoch [1/30] Train Loss: 2.0883 Train Acc: 27.53% | Val Loss: 1.3100 Val Acc: 40.80%\n",
            "Epoch [2/30] Train Loss: 1.1569 Train Acc: 56.15% | Val Loss: 1.1187 Val Acc: 54.18%\n",
            "Epoch [3/30] Train Loss: 0.8844 Train Acc: 72.91% | Val Loss: 0.9851 Val Acc: 63.86%\n",
            "Epoch [4/30] Train Loss: 0.7055 Train Acc: 82.69% | Val Loss: 0.9117 Val Acc: 65.78%\n",
            "Epoch [5/30] Train Loss: 0.5666 Train Acc: 88.00% | Val Loss: 0.8237 Val Acc: 70.88%\n",
            "Epoch [6/30] Train Loss: 0.4590 Train Acc: 91.20% | Val Loss: 0.7555 Val Acc: 74.28%\n",
            "Epoch [7/30] Train Loss: 0.3719 Train Acc: 94.20% | Val Loss: 0.7420 Val Acc: 72.88%\n",
            "Epoch [8/30] Train Loss: 0.3012 Train Acc: 95.38% | Val Loss: 0.6975 Val Acc: 74.35%\n",
            "Epoch [9/30] Train Loss: 0.2437 Train Acc: 96.85% | Val Loss: 0.6805 Val Acc: 74.87%\n",
            "Epoch [10/30] Train Loss: 0.1976 Train Acc: 97.69% | Val Loss: 0.6198 Val Acc: 78.57%\n",
            "Epoch [11/30] Train Loss: 0.1587 Train Acc: 98.72% | Val Loss: 0.6170 Val Acc: 78.05%\n",
            "Epoch [12/30] Train Loss: 0.1263 Train Acc: 99.26% | Val Loss: 0.6118 Val Acc: 78.49%\n",
            "Epoch [13/30] Train Loss: 0.1032 Train Acc: 99.41% | Val Loss: 0.5938 Val Acc: 78.94%\n",
            "Epoch [14/30] Train Loss: 0.0854 Train Acc: 99.75% | Val Loss: 0.5905 Val Acc: 79.75%\n",
            "Epoch [15/30] Train Loss: 0.0712 Train Acc: 99.75% | Val Loss: 0.5743 Val Acc: 79.75%\n",
            "Epoch [16/30] Train Loss: 0.0596 Train Acc: 99.90% | Val Loss: 0.5710 Val Acc: 79.67%\n",
            "Epoch [17/30] Train Loss: 0.0508 Train Acc: 99.95% | Val Loss: 0.5651 Val Acc: 79.67%\n",
            "Epoch [18/30] Train Loss: 0.0443 Train Acc: 99.95% | Val Loss: 0.5693 Val Acc: 80.19%\n",
            "Epoch [19/30] Train Loss: 0.0393 Train Acc: 99.95% | Val Loss: 0.5671 Val Acc: 80.12%\n",
            "Epoch [20/30] Train Loss: 0.0349 Train Acc: 99.95% | Val Loss: 0.5660 Val Acc: 80.12%\n",
            "Epoch [21/30] Train Loss: 0.0311 Train Acc: 100.00% | Val Loss: 0.5726 Val Acc: 79.53%\n",
            "Epoch [22/30] Train Loss: 0.0280 Train Acc: 100.00% | Val Loss: 0.5758 Val Acc: 79.67%\n",
            "Epoch [23/30] Train Loss: 0.0258 Train Acc: 99.95% | Val Loss: 0.5832 Val Acc: 79.75%\n",
            "\n",
            "✓ 早停觸發於 Epoch 23\n",
            "\n",
            "============================================================\n",
            "Final Evaluation on Test Set:\n",
            "Test Loss: 0.5693 Test Accuracy: 80.19%\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "label_test = data_test.target\n",
        "label_train = data_train.target\n",
        "category_names_test = data_test.target_names\n",
        "list_category = sorted(zip(label_test, category_names_test))\n",
        "category_names = {i: category_names_test for i, (_, category_names_test) in enumerate(list_category)}\n",
        "\n",
        "print(\"Building vocabulary from training data...\")\n",
        "preprocessor = TextPreprocessor()\n",
        "\n",
        "vocab = preprocessor.build_vocab(data_train_df[\"Text\"], min_freq=4)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = Dataset(data_train_df, preprocessor, max_len=30)\n",
        "test_dataset = Dataset(data_test_df, preprocessor, max_len=30)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model = TextCNN(len(vocab), embed_dim=100, num_filters=100, filter_sizes=[2, 3, 4], num_classes=4, dropout=0.5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00025, weight_decay=0.0001)\n",
        "\n",
        "# Train model\n",
        "print(\"\\nTraining model...\")\n",
        "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=30, num_classes=4)\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Final Evaluation on Test Set:\")\n",
        "test_loss, test_acc = evaluate_model(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f} Test Accuracy: {test_acc:.2f}%\")\n",
        "print(\"=\" * 60)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

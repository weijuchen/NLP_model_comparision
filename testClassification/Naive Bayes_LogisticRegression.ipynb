{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b59ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "#  先熟悉20newsgroups\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 載入訓練資料\n",
    "train_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# 載入測試資料\n",
    "test_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# 查看資料結構\n",
    "print(len(train_data.data))  # 約 11314 筆\n",
    "\n",
    "\n",
    "# 參考資料  https://scikit-learn.cn/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a175340d-67a0-4c42-9662-92b05320e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))  # check type\n",
    "print(train_data.keys()) # check attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ddc09fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.target_names)  # 20 個主題print(train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "347f0554-a050-4e24-be29-2bea8436cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 4 4 ... 3 1 8]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a400ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(train_data.data[0])  # 第一篇文章內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e2d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(train_data.target[0])  # 該篇文章的標籤（整數編碼）  對應的類別數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ae3cb-8889-4ab2-ad4a-86880c2ed068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import libraries\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4164f3c-2b8f-4943-8056-c7e88af214ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "alt.atheism\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data= fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "print(data.target_names)\n",
    "print(data.target_names[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5800aed2-195d-4a79-b8ca-6c28a8e92d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.sport.hockey', 'comp.sys.ibm.pc.hardware', 'talk.politics.mideast', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n"
     ]
    }
   ],
   "source": [
    "#  依照 data.target 中的每個數字(共計 18846 筆)，找到 data.target_name (僅有20種)所對應的文字\n",
    "import pandas as pd\n",
    "data_category=[]\n",
    "for i in data.target:\n",
    "    data_category.append(data.target_names[i])\n",
    "print(data_category[:5])   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274130a2-8ab1-46e1-92c7-6043aa809817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn it into a dataframe\n",
    "\n",
    "data_df=pd.DataFrame(data.target,columns=['Category_No'])\n",
    "\n",
    "\n",
    "data_df['Category_No'].value_counts()    # 了解每個類別的數量\n",
    "data_df['Text'] = data.data    # 將文字放入dataframe\n",
    "data_df['Category_Name']=data_category  #將類別名稱放入dataframe\n",
    "# data_df.head(5)\n",
    "\n",
    "# data_df=data_df[:5]\n",
    "# data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b6a371-b076-444a-9d6f-f04f2851e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import maven_text_preprocessing\n",
    "import maven_text_preprocessing_v2\n",
    "# import necessary libraries\n",
    "# import pandas as pd\n",
    "# import spacy\n",
    "\n",
    "# # download the spacy model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # helper functions from text preprocessing section\n",
    "# def lower_replace(series):\n",
    "#     output = series.str.lower()\n",
    "#     output = output.str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "#     output = output.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "#     return output\n",
    "\n",
    "# def token_lemma_nonstop(text):\n",
    "#     doc = nlp(text)\n",
    "#     output = [token.lemma_ for token in doc if not token.is_stop]\n",
    "#     return ' '.join(output)\n",
    "\n",
    "# def clean_and_normalize(series):\n",
    "#     output = lower_replace(series)\n",
    "#     output = output.apply(token_lemma_nonstop)\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45b1a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3f1047597e433294e75c6d5b047c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/18846 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_No</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category_Name</th>\n",
       "      <th>Text_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>\\n\\n sure basher pen fan pretty confused lack ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>brother market highperformance video card supp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_No                                               Text  \\\n",
       "0           10  \\n\\nI am sure some bashers of Pens fans are pr...   \n",
       "1            3  My brother is in the market for a high-perform...   \n",
       "\n",
       "              Category_Name                                         Text_Clean  \n",
       "0          rec.sport.hockey  \\n\\n sure basher pen fan pretty confused lack ...  \n",
       "1  comp.sys.ibm.pc.hardware  brother market highperformance video card supp...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply them to the reviews\n",
    "import swifter\n",
    "data_df['Text_Clean'] = maven_text_preprocessing_v2.clean_and_normalize(data_df['Text'])\n",
    "\n",
    "data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fff3466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\n\\nI am sure some bashers of Pens fans are pr...\n",
       "1        My brother is in the market for a high-perform...\n",
       "2        \\n\\n\\n\\n\\tFinally you said what you dream abou...\n",
       "3        \\nThink!\\n\\nIt's the SCSI card doing the DMA t...\n",
       "4        1)    I have an old Jasmine drive which I cann...\n",
       "                               ...                        \n",
       "18841    DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...\n",
       "18842    \\nNot in isolated ground recepticles (usually ...\n",
       "18843    I just installed a DX2-66 CPU in a clone mothe...\n",
       "18844    \\nWouldn't this require a hyper-sphere.  In 3-...\n",
       "18845    After a tip from Gary Crum (crum@fcom.cc.utah....\n",
       "Name: Text, Length: 18846, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # 讓 apply() 可以顯示進度\n",
    "data_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50daabd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data_df['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "becd1c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18841    dn nyedacnsvaxuwecedu david nye \\n dn neurolog...\n",
       "18842    \\n isolated ground recepticle usually unusual ...\n",
       "18843    instal dx266 cpu clone motherboard try mount c...\n",
       "18844    \\n not require hypersphere   3space 4 point sp...\n",
       "18845    tip gary crum crumfcomccutahedu get phone \\n p...\n",
       "Name: Text_Clean, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Text_Clean'][18841:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c47cb-b402-4c80-af05-a577abe1beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create a count vectorizer matrix\n",
    "\n",
    "cv = CountVectorizer(stop_words=\"english\",min_df=0.01)\n",
    "# cv = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=.2)\n",
    "X = cv.fit_transform(data_df.Text_Clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e1dfe86-fe68-415a-86d4-bebf59efc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the features / inputs X\n",
    "X_df = pd.DataFrame(X.toarray(), columns=cv.get_feature_names_out())\n",
    "# X_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f73c5a8-c9be-4eba-a555-f2dec2c30726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                rec.sport.hockey\n",
       "1        comp.sys.ibm.pc.hardware\n",
       "2           talk.politics.mideast\n",
       "3        comp.sys.ibm.pc.hardware\n",
       "4           comp.sys.mac.hardware\n",
       "                   ...           \n",
       "18841                     sci.med\n",
       "18842             sci.electronics\n",
       "18843    comp.sys.ibm.pc.hardware\n",
       "18844               comp.graphics\n",
       "18845                   rec.autos\n",
       "Name: Category_Name, Length: 18846, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the target / outpupt\n",
    "# y = data_df.Category_No\n",
    "y = data_df.Category_Name\n",
    "y\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ab509-2b11-416d-9b7e-adbcfa96b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.34      0.47      0.40       151\n",
      "           comp.graphics       0.45      0.41      0.43       202\n",
      " comp.os.ms-windows.misc       0.43      0.42      0.42       195\n",
      "comp.sys.ibm.pc.hardware       0.41      0.49      0.44       183\n",
      "   comp.sys.mac.hardware       0.53      0.45      0.49       205\n",
      "          comp.windows.x       0.61      0.56      0.59       215\n",
      "            misc.forsale       0.70      0.63      0.66       193\n",
      "               rec.autos       0.56      0.56      0.56       196\n",
      "         rec.motorcycles       0.29      0.60      0.39       168\n",
      "      rec.sport.baseball       0.60      0.66      0.63       211\n",
      "        rec.sport.hockey       0.76      0.57      0.65       198\n",
      "               sci.crypt       0.69      0.59      0.63       201\n",
      "         sci.electronics       0.50      0.47      0.48       202\n",
      "                 sci.med       0.59      0.62      0.61       194\n",
      "               sci.space       0.63      0.50      0.55       189\n",
      "  soc.religion.christian       0.58      0.63      0.61       202\n",
      "      talk.politics.guns       0.57      0.58      0.58       188\n",
      "   talk.politics.mideast       0.65      0.58      0.61       182\n",
      "      talk.politics.misc       0.37      0.33      0.35       159\n",
      "      talk.religion.misc       0.32      0.18      0.23       136\n",
      "\n",
      "                accuracy                           0.52      3770\n",
      "               macro avg       0.53      0.51      0.52      3770\n",
      "            weighted avg       0.54      0.52      0.52      3770\n",
      "\n",
      "Accuracy: 0.5214854111405836\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# model  (Naive Bayes)\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fbdac-1258-4240-b023-2fc1c1a165f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f988a776-33d7-49ac-b5e6-1d0e11460bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6544eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tfidf vectorizer matrix\n",
    "tv = TfidfVectorizer(stop_words='english', min_df=.01)\n",
    "# tv = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=.2)\n",
    "Xt = tv.fit_transform(data_df.Text_Clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a55d8d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>worth</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 1005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        10  100  1000   11        12   13   14   15   16   17  ...  world  \\\n",
       "0      0.0  0.0   0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1      0.0  0.0   0.0  0.0  0.208156  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2      0.0  0.0   0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "3      0.0  0.0   0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4      0.0  0.0   0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "...    ...  ...   ...  ...       ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "18841  0.0  0.0   0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "18842  0.0  0.0   0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "18843  0.0  0.0   0.0  0.0  0.250373  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "18844  0.0  0.0   0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "18845  0.0  0.0   0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "       worry  worth  write     wrong  yeah      year  yes  york  young  \n",
       "0        0.0    0.0    0.0  0.000000   0.0  0.000000  0.0   0.0    0.0  \n",
       "1        0.0    0.0    0.0  0.000000   0.0  0.000000  0.0   0.0    0.0  \n",
       "2        0.0    0.0    0.0  0.000000   0.0  0.083867  0.0   0.0    0.0  \n",
       "3        0.0    0.0    0.0  0.000000   0.0  0.000000  0.0   0.0    0.0  \n",
       "4        0.0    0.0    0.0  0.000000   0.0  0.000000  0.0   0.0    0.0  \n",
       "...      ...    ...    ...       ...   ...       ...  ...   ...    ...  \n",
       "18841    0.0    0.0    0.0  0.000000   0.0  0.097788  0.0   0.0    0.0  \n",
       "18842    0.0    0.0    0.0  0.000000   0.0  0.000000  0.0   0.0    0.0  \n",
       "18843    0.0    0.0    0.0  0.000000   0.0  0.000000  0.0   0.0    0.0  \n",
       "18844    0.0    0.0    0.0  0.231095   0.0  0.000000  0.0   0.0    0.0  \n",
       "18845    0.0    0.0    0.0  0.000000   0.0  0.000000  0.0   0.0    0.0  \n",
       "\n",
       "[18846 rows x 1005 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt_df = pd.DataFrame(Xt.toarray(), columns=tv.get_feature_names_out())\n",
    "Xt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67b1e3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            rec.sport.hockey\n",
       "1    comp.sys.ibm.pc.hardware\n",
       "2       talk.politics.mideast\n",
       "3    comp.sys.ibm.pc.hardware\n",
       "4       comp.sys.mac.hardware\n",
       "Name: Category_Name, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the target / output y\n",
    "yt = data_df.Category_Name\n",
    "yt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82202ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.44      0.48      0.46       151\n",
      "           comp.graphics       0.53      0.50      0.52       202\n",
      " comp.os.ms-windows.misc       0.54      0.45      0.49       195\n",
      "comp.sys.ibm.pc.hardware       0.46      0.51      0.48       183\n",
      "   comp.sys.mac.hardware       0.58      0.50      0.54       205\n",
      "          comp.windows.x       0.59      0.58      0.59       215\n",
      "            misc.forsale       0.66      0.62      0.64       193\n",
      "               rec.autos       0.57      0.53      0.55       196\n",
      "         rec.motorcycles       0.31      0.55      0.40       168\n",
      "      rec.sport.baseball       0.64      0.63      0.63       211\n",
      "        rec.sport.hockey       0.77      0.66      0.71       198\n",
      "               sci.crypt       0.72      0.62      0.66       201\n",
      "         sci.electronics       0.48      0.48      0.48       202\n",
      "                 sci.med       0.59      0.72      0.65       194\n",
      "               sci.space       0.53      0.59      0.56       189\n",
      "  soc.religion.christian       0.61      0.69      0.65       202\n",
      "      talk.politics.guns       0.59      0.59      0.59       188\n",
      "   talk.politics.mideast       0.66      0.63      0.65       182\n",
      "      talk.politics.misc       0.47      0.48      0.47       159\n",
      "      talk.religion.misc       0.36      0.13      0.19       136\n",
      "\n",
      "                accuracy                           0.55      3770\n",
      "               macro avg       0.56      0.55      0.55      3770\n",
      "            weighted avg       0.56      0.55      0.55      3770\n",
      "\n",
      "Accuracy: 0.5214854111405836\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "Xt_train, Xt_test, yt_train, yt_test = train_test_split(Xt_df, yt, test_size=0.2, random_state=42)\n",
    "\n",
    "# model\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(Xt_train, yt_train)\n",
    "\n",
    "# predict\n",
    "y_pred_lr = model_lr.predict(Xt_test)\n",
    "\n",
    "# evaluate\n",
    "print(classification_report(yt_test, y_pred_lr))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74537d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_No</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category_Name</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>predictions_nb</th>\n",
       "      <th>predictions_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n(about my reply)\\n\\n\\nIt a society that is c...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>\\n reply \\n\\n\\n society constantly verge flame...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.203967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10653</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n: There are a couple of things about your p...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>\\n  couple thing post thread \\n  little confu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category_No                                               Text  \\\n",
       "7071             0  \\n(about my reply)\\n\\n\\nIt a society that is c...   \n",
       "10653            0   \\n: There are a couple of things about your p...   \n",
       "\n",
       "      Category_Name                                         Text_Clean  \\\n",
       "7071    alt.atheism  \\n reply \\n\\n\\n society constantly verge flame...   \n",
       "10653   alt.atheism   \\n  couple thing post thread \\n  little confu...   \n",
       "\n",
       "       predictions_nb  predictions_lr  \n",
       "7071              1.0        0.203967  \n",
       "10653             1.0        0.589847  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest priority reviews\n",
    "import numpy as np\n",
    "\n",
    "data_df['predictions_nb'] = model_nb.predict_proba(X_df)[:, 0]\n",
    "data_df['predictions_lr'] = model_lr.predict_proba(Xt_df)[:, 0]\n",
    "data_df.sort_values('predictions_nb', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c45a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_No</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category_Name</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>predictions_nb</th>\n",
       "      <th>predictions_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0</td>\n",
       "      <td>This response originally fell into a bit bucke...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>response originally fall bit bucket   m repost...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11166</th>\n",
       "      <td>0</td>\n",
       "      <td>Archive-name: atheism/introduction\\nAlt-atheis...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>archivename atheismintroduction \\n altatheisma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category_No                                               Text  \\\n",
       "4855             0  This response originally fell into a bit bucke...   \n",
       "11166            0  Archive-name: atheism/introduction\\nAlt-atheis...   \n",
       "\n",
       "      Category_Name                                         Text_Clean  \\\n",
       "4855    alt.atheism  response originally fall bit bucket   m repost...   \n",
       "11166   alt.atheism  archivename atheismintroduction \\n altatheisma...   \n",
       "\n",
       "       predictions_nb  predictions_lr  \n",
       "4855              1.0        0.932616  \n",
       "11166             1.0        0.916527  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_df['predictions_nb'] = model_nb.predict_proba(X_df)[:, 0]\n",
    "data_df['predictions_lr'] = model_lr.predict_proba(Xt_df)[:, 0]\n",
    "data_df.sort_values('predictions_lr', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd5fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_basics)",
   "language": "python",
   "name": "nlp_basics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

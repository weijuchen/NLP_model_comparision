{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90af2072",
   "metadata": {},
   "source": [
    "# 1. Familiar with 20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  先熟悉20newsgroups\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 載入訓練資料\n",
    "train_data = fetch_20newsgroups(subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "\n",
    "# 載入測試資料\n",
    "test_data = fetch_20newsgroups(subset=\"test\", remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "\n",
    "# 查看資料結構\n",
    "print(len(train_data.data))  # 約 11314 筆\n",
    "\n",
    "\n",
    "# 參考資料  https://scikit-learn.cn/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a175340d-67a0-4c42-9662-92b05320e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))  # check type\n",
    "print(train_data.keys()) # check attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.target_names)  # 20 個主題 (topics)  print(train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "347f0554-a050-4e24-be29-2bea8436cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 4 4 ... 3 1 8]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a400ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(train_data.data[0])  # 第一篇文章內容 Check the first article's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(train_data.target[0])  # 該篇文章的標籤（整數編碼）  對應的類別數字  Check the first article's label number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d093d4",
   "metadata": {},
   "source": [
    "# 2.Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49ae3cb-8889-4ab2-ad4a-86880c2ed068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ad0d9",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4164f3c-2b8f-4943-8056-c7e88af214ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "alt.atheism\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data= fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=46)\n",
    "data_train = fetch_20newsgroups(\n",
    "    subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"), shuffle=True, random_state=46\n",
    ")\n",
    "data_test = fetch_20newsgroups(\n",
    "    subset=\"test\",\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    shuffle=True,\n",
    "    random_state=46,\n",
    ")\n",
    "print(data.target_names)\n",
    "print(data.target_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5800aed2-195d-4a79-b8ca-6c28a8e92d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos', 'sci.space', 'sci.electronics', 'comp.sys.mac.hardware', 'talk.politics.mideast']\n",
      "['talk.politics.mideast', 'talk.politics.mideast', 'comp.graphics', 'alt.atheism', 'talk.politics.mideast']\n"
     ]
    }
   ],
   "source": [
    "#  依照 data.target 中的每個數字(共計 18846 筆)，找到 data.target_name (僅有20種)所對應的文字\n",
    "import pandas as pd\n",
    "# data_category=[]\n",
    "# for i in data.target:\n",
    "#     data_category.append(data.target_names[i])\n",
    "# print(data_category[:5])   \n",
    "\n",
    "data_train_category = []\n",
    "for i in data_train.target:\n",
    "    data_train_category.append(data_train.target_names[i])\n",
    "print(data_train_category[:5])\n",
    "\n",
    "\n",
    "data_test_category=[]\n",
    "for i in data_test.target:\n",
    "    data_test_category.append(data_test.target_names[i])\n",
    "print(data_test_category[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274130a2-8ab1-46e1-92c7-6043aa809817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_No</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>\\n\\n\\nAll Muslims knew that the whole thing wa...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>5 Apr 93\\n  MOSCOW (UPI) --\\n        ...\\n    ...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nThe 68070 is made by someone other than Moto...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nOkay, I see smilies, so this isn't...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>\\n\\nYes, it is.  I have taken photos of it's m...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_No                                               Text  \\\n",
       "0           17  \\n\\n\\nAll Muslims knew that the whole thing wa...   \n",
       "1           17  5 Apr 93\\n  MOSCOW (UPI) --\\n        ...\\n    ...   \n",
       "2            1  \\nThe 68070 is made by someone other than Moto...   \n",
       "3            0  \\n\\n\\n\\n\\n\\nOkay, I see smilies, so this isn't...   \n",
       "4           17  \\n\\nYes, it is.  I have taken photos of it's m...   \n",
       "\n",
       "           Category_Name  \n",
       "0  talk.politics.mideast  \n",
       "1  talk.politics.mideast  \n",
       "2          comp.graphics  \n",
       "3            alt.atheism  \n",
       "4  talk.politics.mideast  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn it into a dataframe\n",
    "\n",
    "# data_df=pd.DataFrame(data.target,columns=['Category_No'])\n",
    "\n",
    "data_train_df = pd.DataFrame(data_train.target, columns=[\"Category_No\"])\n",
    "data_test_df = pd.DataFrame(data_test.target, columns=[\"Category_No\"])\n",
    "\n",
    "\n",
    "# data_df['Category_No'].value_counts()    # 了解每個類別的數量\n",
    "# data_df['Text'] = data.data    # 將文字放入dataframe\n",
    "data_train_df['Text']=data_train.data\n",
    "data_test_df['Text'] = data_test.data\n",
    "\n",
    "\n",
    "# data_df['Category_Name']=data_category  #將類別名稱放入dataframe\n",
    "\n",
    "data_train_df[\"Category_Name\"] = data_train_category\n",
    "data_test_df[\"Category_Name\"] = data_test_category\n",
    "\n",
    "data_train_df.head(5)\n",
    "data_test_df.head(5)\n",
    "\n",
    "\n",
    "# data_df.head(5)\n",
    "\n",
    "# data_df=data_df[:5]\n",
    "# data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b6a371-b076-444a-9d6f-f04f2851e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import maven_text_preprocessing_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c9a449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e502f37f904b429da8d75e3fa55962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/11314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_No</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category_Name</th>\n",
       "      <th>Text_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Archive-name: rec-autos/part4\\n\\n[this article...</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>archive rec auto part4 article pair article co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>\\nA freeze dried Tootsie Roll (tm).  The actua...</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>freeze dry tootsie roll tm actual taste sens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_No                                               Text  \\\n",
       "0            7  Archive-name: rec-autos/part4\\n\\n[this article...   \n",
       "1           14  \\nA freeze dried Tootsie Roll (tm).  The actua...   \n",
       "\n",
       "  Category_Name                                         Text_Clean  \n",
       "0     rec.autos  archive rec auto part4 article pair article co...  \n",
       "1     sci.space    freeze dry tootsie roll tm actual taste sens...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_df[\"Text_Clean\"] = maven_text_preprocessing_v2.clean_and_normalize(data_train_df[\"Text\"])\n",
    "data_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "810cca34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bae0b9278934830aa2e0337c6678a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_No</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category_Name</th>\n",
       "      <th>Text_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>\\n\\n\\nAll Muslims knew that the whole thing wa...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>muslims know thing set destroy iraq liberate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>5 Apr 93\\n  MOSCOW (UPI) --\\n        ...\\n    ...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>5 apr 93 moscow upi s horrible people try wife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_No                                               Text  \\\n",
       "0           17  \\n\\n\\nAll Muslims knew that the whole thing wa...   \n",
       "1           17  5 Apr 93\\n  MOSCOW (UPI) --\\n        ...\\n    ...   \n",
       "\n",
       "           Category_Name                                         Text_Clean  \n",
       "0  talk.politics.mideast    muslims know thing set destroy iraq liberate...  \n",
       "1  talk.politics.mideast  5 apr 93 moscow upi s horrible people try wife...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_df[\"Text_Clean\"] = maven_text_preprocessing_v2.clean_and_normalize(data_test_df[\"Text\"])\n",
    "data_test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354cba71",
   "metadata": {},
   "source": [
    "### 2-1 Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "273c47cb-b402-4c80-af05-a577abe1beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer matrix\n",
    "\n",
    "# modify min_df parameter to improve accuracy\n",
    "\n",
    "cv = CountVectorizer(stop_words=\"english\", max_df=0.75, ngram_range=(1, 2))\n",
    "# cv = CountVectorizer(stop_words=\"english\", min_df=5, max_df=0.75, ngram_range=(1, 2))\n",
    "\n",
    "# cv = CountVectorizer(stop_words=\"english\",min_df=0.01)\n",
    "# cv = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=.2)\n",
    "X_train = cv.fit_transform(data_train_df.Text_Clean)\n",
    "X_test = cv.transform(data_test_df.Text_Clean)\n",
    "# X_test = cv.fit_transform(data_test_df.Text_Clean)  wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dfe86-fe68-415a-86d4-bebf59efc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the features / inputs\n",
    "X_train_df = pd.DataFrame(X_train.toarray(), columns=cv.get_feature_names_out())\n",
    "X_test_df = pd.DataFrame(X_test.toarray(), columns=cv.get_feature_names_out())\n",
    "X_test_df.head(3)\n",
    "# X_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f73c5a8-c9be-4eba-a555-f2dec2c30726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the target / outpupt\n",
    "# y = data_df.Category_No\n",
    "y_train=data_train_df.Category_Name\n",
    "y_test=data_test_df.Category_Name\n",
    "\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50099af1",
   "metadata": {},
   "source": [
    "### 2.2 TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9343a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf vectorizer code\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# modify min_df parameter to improve accuracy\n",
    "\n",
    "tv = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), min_df=1, max_df=0.75)\n",
    "# tv = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), min_df=5, max_df=0.75)\n",
    "\n",
    "X_train_tf= tv.fit_transform(data_train_df.Text_Clean)\n",
    "X_test_tf=tv.transform(data_test_df.Text_Clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the features / inputs\n",
    "\n",
    "X_train_tf_df = pd.DataFrame(X_train_tf.toarray(), columns=cv.get_feature_names_out())\n",
    "X_test_tf_df = pd.DataFrame(X_test_tf.toarray(), columns=cv.get_feature_names_out())\n",
    "X_train_tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aca43831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 00</th>\n",
       "      <th>00 01</th>\n",
       "      <th>00 10</th>\n",
       "      <th>00 book</th>\n",
       "      <th>00 good</th>\n",
       "      <th>00 new</th>\n",
       "      <th>00 pm</th>\n",
       "      <th>00 shipping</th>\n",
       "      <th>00 solar</th>\n",
       "      <th>...</th>\n",
       "      <th>zt</th>\n",
       "      <th>zu</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zur</th>\n",
       "      <th>zv</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx 11</th>\n",
       "      <th>zy</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  00 00  00 01  00 10  00 book  00 good  00 new  00 pm  00 shipping  \\\n",
       "0  0.0    0.0    0.0    0.0      0.0      0.0     0.0    0.0          0.0   \n",
       "1  0.0    0.0    0.0    0.0      0.0      0.0     0.0    0.0          0.0   \n",
       "2  0.0    0.0    0.0    0.0      0.0      0.0     0.0    0.0          0.0   \n",
       "3  0.0    0.0    0.0    0.0      0.0      0.0     0.0    0.0          0.0   \n",
       "4  0.0    0.0    0.0    0.0      0.0      0.0     0.0    0.0          0.0   \n",
       "\n",
       "   00 solar  ...   zt   zu  zubov  zuma  zur   zv   zx  zx 11   zy   zz  \n",
       "0       0.0  ...  0.0  0.0    0.0   0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "1       0.0  ...  0.0  0.0    0.0   0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "2       0.0  ...  0.0  0.0    0.0   0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "3       0.0  ...  0.0  0.0    0.0   0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "4       0.0  ...  0.0  0.0    0.0   0.0  0.0  0.0  0.0    0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 27407 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3386297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the target / outpupt\n",
    "# y = data_df.Category_No\n",
    "y_train_tf = data_train_df.Category_Name\n",
    "y_test_tf = data_test_df.Category_Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fda8bb",
   "metadata": {},
   "source": [
    "# 3. Model Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6000ec",
   "metadata": {},
   "source": [
    "### 3.1 Linear model: Naive Bayes with count vectorizer matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb5a674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.25      0.37       319\n",
      "           comp.graphics       0.67      0.70      0.69       389\n",
      " comp.os.ms-windows.misc       0.71      0.07      0.12       394\n",
      "comp.sys.ibm.pc.hardware       0.57      0.67      0.62       392\n",
      "   comp.sys.mac.hardware       0.81      0.49      0.61       385\n",
      "          comp.windows.x       0.49      0.85      0.62       395\n",
      "            misc.forsale       0.85      0.68      0.75       390\n",
      "               rec.autos       0.88      0.64      0.74       396\n",
      "         rec.motorcycles       0.95      0.54      0.69       398\n",
      "      rec.sport.baseball       0.98      0.66      0.79       397\n",
      "        rec.sport.hockey       0.56      0.91      0.69       399\n",
      "               sci.crypt       0.47      0.82      0.59       396\n",
      "         sci.electronics       0.71      0.39      0.51       393\n",
      "                 sci.med       0.80      0.75      0.77       396\n",
      "               sci.space       0.68      0.77      0.72       394\n",
      "  soc.religion.christian       0.46      0.88      0.60       398\n",
      "      talk.politics.guns       0.60      0.59      0.59       364\n",
      "   talk.politics.mideast       0.44      0.87      0.58       376\n",
      "      talk.politics.misc       0.53      0.43      0.47       310\n",
      "      talk.religion.misc       0.69      0.04      0.08       251\n",
      "\n",
      "                accuracy                           0.62      7532\n",
      "               macro avg       0.68      0.60      0.58      7532\n",
      "            weighted avg       0.68      0.62      0.59      7532\n",
      "\n",
      "Accuracy: 0.6163037705788635\n"
     ]
    }
   ],
   "source": [
    "# model  (Naive Bayes)\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065958c7",
   "metadata": {},
   "source": [
    "### 3.2 Linear model: Naive Bayes with TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ab509-2b11-416d-9b7e-adbcfa96b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.68      0.22      0.33       319\n",
      "           comp.graphics       0.64      0.69      0.66       389\n",
      " comp.os.ms-windows.misc       0.66      0.57      0.61       394\n",
      "comp.sys.ibm.pc.hardware       0.61      0.71      0.66       392\n",
      "   comp.sys.mac.hardware       0.76      0.66      0.71       385\n",
      "          comp.windows.x       0.78      0.78      0.78       395\n",
      "            misc.forsale       0.77      0.76      0.76       390\n",
      "               rec.autos       0.82      0.73      0.77       396\n",
      "         rec.motorcycles       0.84      0.75      0.79       398\n",
      "      rec.sport.baseball       0.91      0.79      0.85       397\n",
      "        rec.sport.hockey       0.57      0.93      0.71       399\n",
      "               sci.crypt       0.70      0.76      0.73       396\n",
      "         sci.electronics       0.69      0.52      0.59       393\n",
      "                 sci.med       0.82      0.78      0.80       396\n",
      "               sci.space       0.77      0.75      0.76       394\n",
      "  soc.religion.christian       0.39      0.90      0.55       398\n",
      "      talk.politics.guns       0.56      0.71      0.63       364\n",
      "   talk.politics.mideast       0.78      0.81      0.79       376\n",
      "      talk.politics.misc       0.85      0.33      0.47       310\n",
      "      talk.religion.misc       1.00      0.02      0.03       251\n",
      "\n",
      "                accuracy                           0.68      7532\n",
      "               macro avg       0.73      0.66      0.65      7532\n",
      "            weighted avg       0.72      0.68      0.67      7532\n",
      "\n",
      "Accuracy: 0.6785714285714286\n"
     ]
    }
   ],
   "source": [
    "# model  (Naive Bayes)\n",
    "## For this model, setting min_df to 2, 3 or 4 doesn't significantly impact accuracy.\n",
    "# It remains around 68% in both cases.\n",
    "# Setting min_df to 5 has a slight impact on accuracy, reducing it by approximately 1%.\n",
    "\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train_tf, y_train_tf)\n",
    "\n",
    "# predict\n",
    "y_pred_tf_nb = model_nb.predict(X_test_tf)\n",
    "\n",
    "# evaluate\n",
    "print(classification_report(y_test_tf, y_pred_tf_nb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_tf, y_pred_tf_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcdb978",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fbdac-1258-4240-b023-2fc1c1a165f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.3 Linear model: Logistic Regression with TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f988a776-33d7-49ac-b5e6-1d0e11460bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82202ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.50      0.50      0.50       319\n",
      "           comp.graphics       0.63      0.70      0.67       389\n",
      " comp.os.ms-windows.misc       0.64      0.61      0.63       394\n",
      "comp.sys.ibm.pc.hardware       0.68      0.64      0.66       392\n",
      "   comp.sys.mac.hardware       0.73      0.70      0.71       385\n",
      "          comp.windows.x       0.83      0.71      0.76       395\n",
      "            misc.forsale       0.72      0.77      0.75       390\n",
      "               rec.autos       0.76      0.70      0.73       396\n",
      "         rec.motorcycles       0.75      0.76      0.75       398\n",
      "      rec.sport.baseball       0.52      0.84      0.64       397\n",
      "        rec.sport.hockey       0.89      0.87      0.88       399\n",
      "               sci.crypt       0.88      0.66      0.75       396\n",
      "         sci.electronics       0.54      0.60      0.57       393\n",
      "                 sci.med       0.78      0.78      0.78       396\n",
      "               sci.space       0.72      0.73      0.72       394\n",
      "  soc.religion.christian       0.65      0.79      0.71       398\n",
      "      talk.politics.guns       0.57      0.65      0.61       364\n",
      "   talk.politics.mideast       0.84      0.74      0.79       376\n",
      "      talk.politics.misc       0.55      0.46      0.50       310\n",
      "      talk.religion.misc       0.48      0.20      0.28       251\n",
      "\n",
      "                accuracy                           0.68      7532\n",
      "               macro avg       0.68      0.67      0.67      7532\n",
      "            weighted avg       0.69      0.68      0.68      7532\n",
      "\n",
      "Accuracy: 0.6832182687201275\n"
     ]
    }
   ],
   "source": [
    "## This model cannot run with min_df set to 2, 3, or 4 due to insufficient memory on my laptop.\n",
    "\n",
    "\n",
    "# model\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_tf, y_train_tf)\n",
    "\n",
    "# predict\n",
    "y_pred_lr = model_lr.predict(X_test_tf)\n",
    "\n",
    "# evaluate\n",
    "print(classification_report(y_test_tf, y_pred_lr))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.3 Linear SVC model with TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04f554fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399341dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.58      0.51      0.54       319\n",
      "           comp.graphics       0.67      0.72      0.70       389\n",
      " comp.os.ms-windows.misc       0.65      0.63      0.64       394\n",
      "comp.sys.ibm.pc.hardware       0.69      0.67      0.68       392\n",
      "   comp.sys.mac.hardware       0.73      0.73      0.73       385\n",
      "          comp.windows.x       0.83      0.73      0.78       395\n",
      "            misc.forsale       0.70      0.80      0.75       390\n",
      "               rec.autos       0.80      0.72      0.76       396\n",
      "         rec.motorcycles       0.83      0.76      0.79       398\n",
      "      rec.sport.baseball       0.55      0.85      0.67       397\n",
      "        rec.sport.hockey       0.86      0.90      0.88       399\n",
      "               sci.crypt       0.87      0.72      0.79       396\n",
      "         sci.electronics       0.63      0.60      0.61       393\n",
      "                 sci.med       0.79      0.79      0.79       396\n",
      "               sci.space       0.75      0.75      0.75       394\n",
      "  soc.religion.christian       0.63      0.82      0.71       398\n",
      "      talk.politics.guns       0.60      0.67      0.63       364\n",
      "   talk.politics.mideast       0.84      0.76      0.80       376\n",
      "      talk.politics.misc       0.56      0.46      0.51       310\n",
      "      talk.religion.misc       0.49      0.27      0.35       251\n",
      "\n",
      "                accuracy                           0.71      7532\n",
      "               macro avg       0.70      0.69      0.69      7532\n",
      "            weighted avg       0.71      0.71      0.70      7532\n",
      "\n",
      "Accuracy: 0.7060541688794477\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "\n",
    "# min_df= 2 ,accuracy=69%\n",
    "# min_df=1, accuracy=70%\n",
    "\n",
    "model_svc = LinearSVC()\n",
    "model_svc.fit(X_train_tf, y_train_tf)\n",
    "\n",
    "# predict\n",
    "y_pred_svc = model_svc.predict(X_test_tf)\n",
    "\n",
    "# evaluate\n",
    "print(classification_report(y_test_tf, y_pred_svc))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.4 Random Forest with TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a96b7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee43ec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.45      0.38      0.41       319\n",
      "           comp.graphics       0.58      0.61      0.59       389\n",
      " comp.os.ms-windows.misc       0.56      0.58      0.57       394\n",
      "comp.sys.ibm.pc.hardware       0.62      0.59      0.60       392\n",
      "   comp.sys.mac.hardware       0.64      0.65      0.64       385\n",
      "          comp.windows.x       0.69      0.66      0.68       395\n",
      "            misc.forsale       0.65      0.74      0.69       390\n",
      "               rec.autos       0.41      0.66      0.50       396\n",
      "         rec.motorcycles       0.66      0.68      0.67       398\n",
      "      rec.sport.baseball       0.70      0.78      0.74       397\n",
      "        rec.sport.hockey       0.81      0.80      0.81       399\n",
      "               sci.crypt       0.81      0.65      0.72       396\n",
      "         sci.electronics       0.48      0.43      0.45       393\n",
      "                 sci.med       0.70      0.68      0.69       396\n",
      "               sci.space       0.69      0.66      0.68       394\n",
      "  soc.religion.christian       0.56      0.78      0.65       398\n",
      "      talk.politics.guns       0.52      0.59      0.55       364\n",
      "   talk.politics.mideast       0.81      0.70      0.75       376\n",
      "      talk.politics.misc       0.56      0.34      0.42       310\n",
      "      talk.religion.misc       0.28      0.06      0.10       251\n",
      "\n",
      "                accuracy                           0.62      7532\n",
      "               macro avg       0.61      0.60      0.60      7532\n",
      "            weighted avg       0.62      0.62      0.61      7532\n",
      "\n",
      "Accuracy: 0.6157727031332979\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model\n",
    "model_rf = RandomForestClassifier(\n",
    "    n_estimators=100,  # 100 棵決策樹\n",
    "    max_depth=None,  # 允許樹完全生長\n",
    "    min_samples_leaf=1,  # 葉子節點的最小樣本數\n",
    "    random_state=46,\n",
    "    n_jobs=-1,  # 使用所有可用的 CPU 核心加速訓練\n",
    ")\n",
    "\n",
    "\n",
    "# 在訓練數據上訓練模型\n",
    "model_rf.fit(X_train_tf, y_train_tf)\n",
    "\n",
    "##  Predit\n",
    "# 使用訓練好的模型對測試集進行預測\n",
    "y_pred_rf = model_rf.predict(X_test_tf)\n",
    "\n",
    "# evaluate\n",
    "print(classification_report(y_test_tf, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.5 XGBoost with TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6c81f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "y_train_tf_xgb = data_train_df.Category_No\n",
    "y_test_tf_xgb = data_test_df.Category_No\n",
    "print(type(X_train_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "358a22d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練樣本數量 (文檔數): 11314\n",
      "特徵數量 (TF-IDF 維度): 27407\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 獲取矩陣的維度 (行數, 列數)\n",
    "matrix_shape = X_train_tf.shape\n",
    "\n",
    "# 行數是樣本數量 (文檔數量)\n",
    "num_samples = matrix_shape[0]\n",
    "\n",
    "# 列數是特徵數量 (詞彙表大小/max_features)\n",
    "num_features = matrix_shape[1]\n",
    "\n",
    "print(f\"訓練樣本數量 (文檔數): {num_samples}\")\n",
    "print(f\"特徵數量 (TF-IDF 維度): {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_classes = len(np.unique(y_train_tf))\n",
    "\n",
    "# model\n",
    "model_xgb = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    n_estimators=100,  # 提升樹的數量 (Boosting Rounds)\n",
    "    learning_rate=0.1,  # 學習率/步長 (控制每棵樹的貢獻)\n",
    "    max_depth=6,  # 每棵樹的最大深度\n",
    "    num_class=num_classes,  # 多類別分類時必須設定類別數量\n",
    "    eval_metric=\"mlogloss\",  # 評估指標 (多類別對數損失)\n",
    "    use_label_encoder=False,  # 關閉未來會移除的警告\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # 使用所有可用的 CPU 核心加速訓練\n",
    ")\n",
    "\n",
    "# 在訓練數據上訓練模型\n",
    "# early_stopping_rounds 可用於防止過擬合並加速訓練（需要傳入評估集）\n",
    "model_xgb.fit(X_train_tf, y_train_tf_xgb)\n",
    "\n",
    "## Predit\n",
    "# 使用訓練好的模型對測試集進行預測\n",
    "y_pred_xgb = model_xgb.predict(X_test_tf)\n",
    "\n",
    "#   evaluate\n",
    "print(classification_report(y_test_tf_xgb, y_pred_xgb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_tf_xgb, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd5fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_basics)",
   "language": "python",
   "name": "nlp_basics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
